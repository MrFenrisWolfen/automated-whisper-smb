version: "3.8"

services:
  # Whisper GPU
  gpu:
    build:
      context: .            # . F端r das Verzeichnis mit dem Dockerfile (workingdir)
      dockerfile: whisper.dockerfile
    container_name: whisper-gpu
    environment:
      WHISPER_MODEL:  "${WHISPER_MODEL:-medium}"
    volumes:
      - data:/app/audio/data   # Gemountetes Volume vom smb Server
      - cache:/root/.cache/whisper  # Permanente Speicherung von Whisper-Models nach dem 1. Download
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # nutzung der gpu falls vorhanden
    runtime: nvidia  # notwendigkeit um eine gpu unterst端tzung zu haben
    profiles:
      - gpu  # damit bei --profile gpu dieser block genutzt wird
    restart: unless-stopped

  # Whisper CPU
  cpu:
    build:
      context: .            # . F端r das Verzeichnis mit dem Dockerfile (workingdir)
      dockerfile: whisper.dockerfile
    container_name: whisper-cpu
    environment:
      WHISPER_MODEL:  "${WHISPER_MODEL:-small}"
    volumes:
      - data:/app/audio/data   # Gemountetes Volume vom smb Server
      - cache:/root/.cache/whisper  # Permanente Speicherung von Whisper-Models nach dem 1. Download
    profiles:
      - cpu  # Damit bei --profile cpu dieser Block genutzt wird
    restart: unless-stopped

  # SMB
  samba:
    image: dockurr/samba
    container_name: whisper-smb
    environment:
      NAME: "whisper"
      USER: "samba"
      PASS: "secret"
      RW: true
      UID: 1000
      GID: 1000
    ports:
      - "139:139"
      - "445:445"
    volumes:
      - data:/storage  # Gemountetes Volume vom smb Server
    restart: unless-stopped

# Volumes f端r die Daten
volumes:
  data:
  cache:
