version: "3.8"

services:
  # Whisper GPU
  whisper-gpu:
    build:
      context: .            # Verweis auf das Verzeichnis mit dem Dockerfile
      dockerfile: whisper.dockerfile
    container_name: whisper-gpu
    environment:
      WHISPER_MODEL: medium
    volumes:
      - whisper_data:/app/audio/data   # Gemeinsames Volume mit SMB-Server
      - whisper_cache:/root/.cache/whisper  # Persistente Speicherung von Modellen nach dem 1. Download
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # GPU nutzen, falls verfügbar
    runtime: nvidia  # Notwendig für GPU-Unterstützung
    profiles:
      - gpu  # Dieser Service wird nur im GPU-Profil gestartet
    restart: unless-stopped

  # Whisper CPU
  whisper-cpu:
    build:
      context: .            # Verweis auf das Verzeichnis mit dem Dockerfile
      dockerfile: whisper.dockerfile
    container_name: whisper-cpu
    environment:
      WHISPER_MODEL: small
    volumes:
      - whisper_data:/app/audio/data
      - whisper_cache:/root/.cache/whisper
    profiles:
      - cpu  # Dieser Service wird nur im CPU-Profil gestartet
    restart: unless-stopped

  # SMB-Server
  whisper_samba:
    image: dockurr/samba
    container_name: whisper-smb-server
    environment:
      NAME: "whisper"
      USER: "samba"
      PASS: "secret"
      RW: true
      UID: 1000
      GID: 1000
    ports:
      - "139:139"
      - "445:445"
    volumes:
      - whisper_data:/storage
    restart: unless-stopped

# Gemeinsame Volumes
volumes:
  whisper_data:
  whisper_cache:
