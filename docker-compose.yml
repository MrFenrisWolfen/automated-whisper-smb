version: "3.8"

services:
  # Whisper GPU
  whisper:
    build:
      context: .            # Verweis auf das Verzeichnis mit dem Dockerfile
      dockerfile: dockerfile
    container_name: whisper
    environment:
      WHISPER_MODEL: medium
    volumes:
      - whisper_data:/app/audio/data   # Gemeinsames Volume mit SMB-Server
      - whisper_cache:/root/.cache/Whisper  # Persistente Speicherung von Modellen nach dem 1. Download
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # GPU nutzen, falls verf端gbar
    runtime: nvidia  # Notwendig f端r GPU-Unterst端tzung
    profiles:
      - gpu  # Dieser Service wird nur im GPU-Profil gestartet

  # Whisper CPU
  whisper-cpu:
    build:
      context: .            # Verweis auf das Verzeichnis mit dem Dockerfile
      dockerfile: dockerfile
    container_name: whisper_cpu
    environment:
      WHISPER_MODEL: tiny
    volumes:
      - whisper_data:/app/audio/data
      - whisper_cache:/root/.cache/Whisper
    profiles:
      - cpu  # Dieser Service wird nur im CPU-Profil gestartet

  # SMB-Server
  smb:
    image: dperson/samba    # Beispiel-Image f端r SMB-Server
    container_name: smb-server
    ports:
      - "139:139"           # SMB-Port
      - "445:445"           # SMB-Port
    environment:
      - TZ=Europe/Berlin
    volumes:
      - whisper_data:/mnt/shared      # Gemeinsames Volume mit Hauptcontainer

# Gemeinsame Volumes
volumes:
  whisper_data:
  whisper_cache:
